docker-compose.yml

version: "3.8"
services:
  llm-agent:
    image: ghcr.io/ggerganov/llama.cpp:latest
    container_name: code-llm
    command: [ "./server", "-m", "/models/codellama-7b.Q4_K_M.gguf", "-c", "4096", "-n", "-1", "--port", "8000" ]
    ports:
      - "8000:8000"
    volumes:
      - ./models:/models
    restart: unless-stopped

docker-compose.yml folder structure

.
├── docker-compose.yml
└── models/
    └── codellama-7b.Q4_K_M.gguf  # (~4-5GB quantized model)

How to Use
	1.	Download a quantized coding model (CodeLlama, Mistral, etc.)
Example site: huggingface.co/TheBloke
	2.	Start the container
docker-compose up -d

curl http://localhost:8000/completion -d '{
  "prompt": "Write a Python function to sort a list",
  "n_predict": 256
}'

----------------------------------
OR
----------------------------------
docker-compose.yml

version: "3.9"
services:
  llm-agent:
    image: ghcr.io/jmorganca/ollama:latest
    container_name: code-llm
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    restart: unless-stopped
    entrypoint: >
      bash -c "
      ollama serve & 
      sleep 2 && 
      ollama run codellama
      "

volumes:
  ollama-data:





-- Create user
INSERT INTO users (
  uuid,
  login,
  name,
  email,
  crypted_password,
  salt,
  active,
  created_at,
  updated_at
)
VALUES (
  '9de0f9ab-3280-46a5-88aa-0c125b5e519c',
  'tempadmin',
  'Temp Admin',
  'tempadmin@example.com',
  '5baa61e4c9b93f3f0682250b6cf8331b7ee68fd8',
  '',
  1,
  CAST((SYSDATE - TO_DATE('1970-01-01','YYYY-MM-DD')) * 86400 * 1000 AS NUMBER),
  CAST((SYSDATE - TO_DATE('1970-01-01','YYYY-MM-DD')) * 86400 * 1000 AS NUMBER)
);

COMMIT;

-- Assign Global Admin role
INSERT INTO user_roles (
  user_uuid,
  role,
  resource_id
)
VALUES (
  '9de0f9ab-3280-46a5-88aa-0c125b5e519c',
  'admin',
  NULL
);

COMMIT;
